#!/usr/bin/env python3
"""
AITuberå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ç°¡å˜ãªã‚³ãƒãƒ³ãƒ‰ã§ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ»ãƒãƒ£ãƒƒãƒˆãƒ»ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
"""

import sys
import argparse
import subprocess
from pathlib import Path

def run_command(command, description):
    """ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ"""
    print(f"\nğŸš€ {description}")
    print(f"å®Ÿè¡Œä¸­: {command}")
    print("-" * 50)
    
    try:
        result = subprocess.run(command, shell=True, check=True)
        print(f"\nâœ… {description}ãŒå®Œäº†ã—ã¾ã—ãŸ")
        return True
    except subprocess.CalledProcessError as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return False

def check_environment():
    """ç’°å¢ƒãƒã‚§ãƒƒã‚¯"""
    print("ğŸ” ç’°å¢ƒã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ã„ã¾ã™...")
    
    # venvã®å­˜åœ¨ç¢ºèª
    venv_path = Path("venv")
    if not venv_path.exists():
        print("âŒ ä»®æƒ³ç’°å¢ƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„: python run.py setup")
        return False
    
    # Pythonã®ç¢ºèª
    try:
        result = subprocess.run("python --version", shell=True, capture_output=True, text=True)
        print(f"âœ… Python: {result.stdout.strip()}")
    except:
        print("âŒ PythonãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False
    
    return True

def main():
    parser = argparse.ArgumentParser(description='AITuberå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ')
    parser.add_argument('command', help='å®Ÿè¡Œã™ã‚‹ã‚³ãƒãƒ³ãƒ‰', choices=[
        'setup', 'train', 'train-quick', 'chat', 'chat-demo', 
        'test', 'test-quick', 'inference', 'inference-demo',
        'prepare-data', 'check-env', 'clean', 'help'
    ])
    parser.add_argument('--no-venv', action='store_true', help='ä»®æƒ³ç’°å¢ƒã‚’ä½¿ç”¨ã—ãªã„')
    
    args = parser.parse_args()
    
    # ãƒ˜ãƒ«ãƒ—è¡¨ç¤º
    if args.command == 'help':
        print("AITuber æœ›æœˆäº¬å­ å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
        print("=" * 40)
        print("åˆ©ç”¨å¯èƒ½ãªã‚³ãƒãƒ³ãƒ‰:")
        print("  setup        - ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—")
        print("  train        - LoRAå­¦ç¿’ã®å®Ÿè¡Œ")
        print("  train-quick  - é«˜é€Ÿå­¦ç¿’ï¼ˆ1ã‚¨ãƒãƒƒã‚¯ï¼‰")
        print("  chat         - ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹")
        print("  chat-demo    - ãƒãƒ£ãƒƒãƒˆãƒ‡ãƒ¢")
        print("  test         - åŒ…æ‹¬çš„ãªãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ")
        print("  test-quick   - é«˜é€Ÿãƒ†ã‚¹ãƒˆ")
        print("  inference    - æ¨è«–ãƒ¢ãƒ¼ãƒ‰ï¼ˆå¯¾è©±ï¼‰")
        print("  inference-demo - æ¨è«–ãƒ‡ãƒ¢")
        print("  prepare-data - ãƒ‡ãƒ¼ã‚¿æº–å‚™")
        print("  check-env    - ç’°å¢ƒãƒã‚§ãƒƒã‚¯")
        print("  clean        - ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤")
        print("  help         - ã“ã®ãƒ˜ãƒ«ãƒ—ã‚’è¡¨ç¤º")
        print("\nä½¿ç”¨ä¾‹:")
        print("  python run.py setup")
        print("  python run.py chat")
        print("  python run.py train")
        return
    
    # ä»®æƒ³ç’°å¢ƒã®ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹
    if args.no_venv:
        python_cmd = "python"
    else:
        if sys.platform == "win32":
            python_cmd = "venv\\Scripts\\python"
        else:
            python_cmd = "source venv/bin/activate && python"
    
    # ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ
    commands = {
        'setup': {
            'cmd': 'python -m venv venv && echo "ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆã—ã¾ã—ãŸã€‚ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:" && echo "1. ä»®æƒ³ç’°å¢ƒã®æœ‰åŠ¹åŒ–" && echo "2. pip install -r requirements.txt"',
            'desc': 'ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—'
        },
        'train': {
            'cmd': f'{python_cmd} train_lora.py --config config.yaml',
            'desc': 'LoRAå­¦ç¿’ã®å®Ÿè¡Œ'
        },
        'train-quick': {
            'cmd': f'{python_cmd} train_lora.py --config config.yaml --epochs 1',
            'desc': 'é«˜é€Ÿå­¦ç¿’ï¼ˆ1ã‚¨ãƒãƒƒã‚¯ï¼‰'
        },
        'chat': {
            'cmd': f'{python_cmd} chat_interface.py',
            'desc': 'ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹'
        },
        'chat-demo': {
            'cmd': f'{python_cmd} chat_interface.py --demo',
            'desc': 'ãƒãƒ£ãƒƒãƒˆãƒ‡ãƒ¢'
        },
        'test': {
            'cmd': f'{python_cmd} test_model.py',
            'desc': 'åŒ…æ‹¬çš„ãªãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ'
        },
        'test-quick': {
            'cmd': f'{python_cmd} test_model.py --quick',
            'desc': 'é«˜é€Ÿãƒ†ã‚¹ãƒˆ'
        },
        'inference': {
            'cmd': f'{python_cmd} inference.py --interactive',
            'desc': 'æ¨è«–ãƒ¢ãƒ¼ãƒ‰ï¼ˆå¯¾è©±ï¼‰'
        },
        'inference-demo': {
            'cmd': f'{python_cmd} inference.py',
            'desc': 'æ¨è«–ãƒ‡ãƒ¢'
        },
        'prepare-data': {
            'cmd': f'cd data/training && {python_cmd} prepare_dataset.py',
            'desc': 'ãƒ‡ãƒ¼ã‚¿æº–å‚™'
        },
        'check-env': {
            'cmd': f'{python_cmd} test_lora_setup.py',
            'desc': 'ç’°å¢ƒãƒã‚§ãƒƒã‚¯'
        },
        'clean': {
            'cmd': 'rm -rf outputs/ __pycache__/ *.pyc .pytest_cache/ test_report*.txt chat_history.json',
            'desc': 'ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤'
        }
    }
    
    if args.command in commands:
        # ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä»¥å¤–ã¯ç’°å¢ƒãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ
        if args.command != 'setup' and args.command != 'clean' and not args.no_venv:
            if not check_environment():
                return
        
        cmd_info = commands[args.command]
        success = run_command(cmd_info['cmd'], cmd_info['desc'])
        
        if not success:
            print("\nâŒ ã‚³ãƒãƒ³ãƒ‰ã®å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ")
            sys.exit(1)
    else:
        print(f"âŒ ä¸æ˜ãªã‚³ãƒãƒ³ãƒ‰: {args.command}")
        print("åˆ©ç”¨å¯èƒ½ãªã‚³ãƒãƒ³ãƒ‰ã‚’ç¢ºèªã™ã‚‹ã«ã¯: python run.py help")
        sys.exit(1)

if __name__ == "__main__":
    main()